{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/notebooks/pipenv\")\n",
    "sys.path.insert(0, \"/notebooks/nebula3_vlm\")\n",
    "sys.path.insert(0, \"/notebooks/nebula3_database\")\n",
    "sys.path.insert(0, \"/notebooks/\")\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import bisect\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import urllib\n",
    "import subprocess\n",
    "import re\n",
    "import tempfile\n",
    "import itertools\n",
    "import torch\n",
    "import spacy\n",
    "# import amrlib\n",
    "# import penman\n",
    "\n",
    "from typing import List, Tuple\n",
    "from operator import itemgetter \n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification, BertTokenizer, BertForSequenceClassification\n",
    "from database.arangodb import DatabaseConnector\n",
    "from config import NEBULA_CONF\n",
    "from movie_db import MOVIE_DB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PIPELINE:\n",
    "    def __init__(self):\n",
    "        config = NEBULA_CONF()\n",
    "        self.db_host = config.get_database_host()\n",
    "        self.database = config.get_playground_name()\n",
    "        self.gdb = DatabaseConnector()\n",
    "        self.db = self.gdb.connect_db(self.database)\n",
    "\n",
    "pipeline = PIPELINE()\n",
    "mdb = MOVIE_DB()\n",
    "from vlm.clip_api import CLIP_API\n",
    "clip=CLIP_API('vit')\n",
    "s2_collection_name = 's2_pipeline_after_gpt'\n",
    "s2_results_orig_collection_name = 's2_pipeline_optim_orig'\n",
    "s2_results_relaxed_collection_name = 's2_pipeline_optim_relaxed'\n",
    "s2_compatibility_collection_name = 's2_pipeline_compatibility_scores'\n",
    "s2_with_compat_collection_name = 's2_pipeline_compatibility_results'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(lst): return [x for l in lst for x in l]\n",
    "\n",
    "def compute_batch_scores(video_emb: torch.Tensor, texts: List[str], normalize=True, **kwargs) -> List[float]:    \n",
    "    emb_batch = clip.clip_batch_encode_text(texts, **kwargs)                           \n",
    "    return (video_emb.expand_as(emb_batch)*emb_batch).sum(dim=1).cpu().numpy()\n",
    "\n",
    "\n",
    "def compute_concat_score(image_emb: torch.Tensor, texts: List[str], join_on=',') -> float:\n",
    "    combined_text = \"\"\n",
    "    for t in [x.strip() for x in texts]:\n",
    "        if t[-1]=='.':\n",
    "            t = t[:-1]       \n",
    "        t+=join_on\n",
    "        t+=' '\n",
    "        combined_text+=t\n",
    "    print(\"Combined: \"+combined_text)\n",
    "    return torch.matmul(image_emb,mdmmt.encode_text(combined_text.strip()) )       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_concept(c):\n",
    "    exp = re.compile(r\"^([a-zA-z]+)-?(\\d*)$\")\n",
    "    r = exp.match(c)\n",
    "    return r.group(1) if r else c\n",
    "\n",
    "class ConceptManager:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def ground_concept(concept):\n",
    "        return transform_concept(concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimilarityManager:\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "    def similarity(self, src, target):\n",
    "        rc = []\n",
    "        s1 = self.nlp(src)\n",
    "        s2 = self.nlp(target)\n",
    "        for w in s1:\n",
    "            # if not w or not w.vector_norm:\n",
    "            #     print('Argghhh 1, bad word:')\n",
    "            #     print(w.text)\n",
    "            if w.pos_ not in ['NOUN', 'ADJ', 'ADV', 'VERB', 'PROPN', 'ADP'] and len(s1)>1:\n",
    "                continue\n",
    "            # for tok in s2:\n",
    "            #     if not tok or not tok.vector_norm:\n",
    "            #         print('Argghhh 2, bad word:')\n",
    "            #         print(tok.text)\n",
    "            #         print(s2.text)\n",
    "            rc.append(max([w.similarity(x) for x in s2]))\n",
    "        return np.mean(rc)\n",
    "        \n",
    "smanager = SimilarityManager()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = lambda x: np.exp(x)/sum(np.exp(x))\n",
    "def normalize(x):\n",
    "    epsilon = 0.00001\n",
    "    if np.std(x) < epsilon:\n",
    "        return np.ones(x.shape)\n",
    "    return (x - np.mean(x)) / np.std(x)\n",
    "\n",
    "class SubsetOptimization:\n",
    "    def __init__(self, video_emb, experts: List, candidates_strings: List[str], coverage_matrix = None, coverage_threshold=1.5, **kwargs):\n",
    "        self.video_emb = video_emb\n",
    "        self.initial_temp = 10\n",
    "        self.final_temp = .001\n",
    "        self.alpha = 0.01\n",
    "        self.theta = 0.9\n",
    "        self.theta1 = 0.5\n",
    "        self.remove_prob_temprature = 5.\n",
    "        self.expert_to_cover_temp = 1.\n",
    "        self.candidate_to_add_cover_temp = 1.\n",
    "        self.candidate_to_add_vlm_temp = 1.\n",
    "        self.reset_every = 5000\n",
    "        self.experts = experts\n",
    "        self.coverage_threshold = coverage_threshold\n",
    "        self.candidates_strings = candidates_strings\n",
    "        self.max_size_coeff = 3.5\n",
    "        print(\"Computing batch similarity...\")\n",
    "        self.candidates_similarity = compute_batch_scores(self.video_emb, self.candidates_strings)\n",
    "        print(\"Done\")\n",
    "        self.opt_results = []\n",
    "        self.smanager = SimilarityManager()\n",
    "\n",
    "        if coverage_matrix is not None:\n",
    "            self.coverage_matrix = coverage_matrix\n",
    "        else:\n",
    "            self.coverage_matrix = np.zeros([len(self.experts),len(self.candidates_strings)])\n",
    "            self.coverage_matrix[:] = np.nan\n",
    "            for i in range(len(experts)):\n",
    "                for j in range(len(candidates_strings)):\n",
    "                    self.coverage_matrix[i][j]=self.concept_similarity(self.experts[i],self.candidates_strings[j])\n",
    "        self.max_size = int(len(self.experts)*self.max_size_coeff)\n",
    "\n",
    "    def concept_similarity(self, concept, sent):        \n",
    "        # return max(self.smanager.similarity(concept,sent))\n",
    "        return self.smanager.similarity(concept,sent)\n",
    "\n",
    "    def get_coverage(self,i,j):        \n",
    "        if np.isnan(self.coverage_matrix[i][j]):\n",
    "            self.coverage_matrix[i][j] = self.concept_similarity(self.experts[i],self.candidates_strings[j])\n",
    "        return self.coverage_matrix[i][j]\n",
    "\n",
    "    # Return, for each expert, the -sum total- of how much it is covered by the state.\n",
    "\n",
    "    def get_expert_coverage(self,state):\n",
    "        return self.coverage_matrix[:,state].sum(axis=1)\n",
    "        # return self.coverage_matrix[:,state].max(axis=1)\n",
    "\n",
    "    def get_state_coverage(self,state) -> float:\n",
    "        # print(\"State coverage for {}:\".format(state))\n",
    "        # print(self.get_expert_coverage(state))\n",
    "        return np.mean(self.get_expert_coverage(state))\n",
    "\n",
    "    # def get_state_coverage(self, state: List[int]) -> float:\n",
    "    #     experts_coverage = [max([self.get_coverage(i,j) for j in state]) for i in range(len(self.experts))]    # A list of partial coverege        \n",
    "    #     return sum(experts_coverage) / len(self.experts)\n",
    "\n",
    "    def get_score(self, state: List[int]) -> float:\n",
    "        if not state:\n",
    "            return 0\n",
    "        coverage_score = self.get_state_coverage(state)   \n",
    "        similarity_score = self.candidates_similarity[state].mean().item()\n",
    "        return (1-self.theta)*coverage_score + self.theta*similarity_score\n",
    "\n",
    "\n",
    "    def prob_to_remove(self, state):\n",
    "        cover = self.get_state_coverage(state)\n",
    "        relative_cover = min(max(cover / self.coverage_threshold,0),1)\n",
    "        rc = np.power(relative_cover,4)\n",
    "        # print(\"Cover, relative cover, prob to remove: {}, {}, {}\".format(cover, relative_cover, rc))\n",
    "        return rc\n",
    "\n",
    "\n",
    "    def candidate_to_add_probs(self, expert_to_cover, anti_state):       \n",
    "        add_cover = normalize(self.coverage_matrix[expert_to_cover][anti_state])\n",
    "        add_similarity = normalize(self.candidates_similarity[anti_state])\n",
    "        # print(\"add_cover:\")\n",
    "        # print(add_cover)\n",
    "        # print(\"add_similarity:\")\n",
    "        # print(add_similarity)\n",
    "        probs = softmax(add_cover*self.candidate_to_add_cover_temp + add_similarity*self.candidate_to_add_vlm_temp)\n",
    "        return probs\n",
    "     \n",
    "    # state here is assumed (and guaranteed on return) to be -sorted-\n",
    "    def get_candidate(self, state: List[int]) -> List[int]:\n",
    "        def compute_state_arrays(s):\n",
    "            s_score = self.candidates_similarity[s]\n",
    "            s_coverage = self.coverage_matrix.mean(axis=0)[s]\n",
    "            s_max_coverage = self.coverage_matrix.max(axis=0)[s]\n",
    "            s_fitscore = (1-self.theta1)*s_coverage+self.theta1*s_score\n",
    "            # print(\"fitscore: {}\".format(s_fitscore))\n",
    "            return (s_score,s_coverage,s_max_coverage,s_fitscore)\n",
    "\n",
    "        if not state:\n",
    "            # print(\"Empty state\")\n",
    "            return [random.randint(0,len(self.candidates_strings)-1)]\n",
    "            \n",
    "        rc = state.copy()\n",
    "        s = np.array(state)\n",
    "        s_score, s_coverage, s_max_coverage, s_fitscore = compute_state_arrays(s)\n",
    "               \n",
    "        if len(state) == self.max_size:\n",
    "            # print(\"Maximum state size, removing\")\n",
    "            idx = np.argmin(s_fitscore)\n",
    "            del rc[idx]\n",
    "            return rc\n",
    "            \n",
    "        remove_sentence = random.random()<self.prob_to_remove(state) or len(state)==len(self.candidates_strings)  \n",
    "        # print(\"coverage of {} is {}, remove?{}\".format(state,self.get_state_coverage(state),remove_sentence))\n",
    "        if remove_sentence:             # We decide to remove a sentence from the set\n",
    "            # print(\"Removing\")\n",
    "            probs = softmax(-s_fitscore*self.remove_prob_temprature)\n",
    "            # print(probs)\n",
    "            idx = np.random.multinomial(1,probs).argmax()\n",
    "            # print(\"removing index: {}\".format(idx))\n",
    "            del rc[idx]                   \n",
    "        else:                           # Add a sentence from the outside\n",
    "            # print(\"Adding\")\n",
    "            anti_state = []\n",
    "            for i in range(len(self.candidates_strings)):\n",
    "                if not i in state:\n",
    "                    anti_state.append(i)\n",
    "            s1 = np.array(anti_state)\n",
    "            s1_score, s1_coverage, s1_max_coverage, s1_fitscore = compute_state_arrays(s1)\n",
    "            # Pick an expert to try and cover\n",
    "            expert_coverage = self.get_expert_coverage(s)\n",
    "            # print(\"expert coverage when adding:\")\n",
    "            # print(list(zip(self.experts,expert_coverage)))\n",
    "            probs = softmax(-expert_coverage*self.expert_to_cover_temp)         # Coverage is in (0,1), so we use low temprature\n",
    "            # print(probs)\n",
    "            expert_to_cover = np.random.multinomial(1,probs).argmax()\n",
    "            # print(\"Trying to cover expert: {}\".format(self.experts[expert_to_cover]))\n",
    "            probs = self.candidate_to_add_probs(expert_to_cover,s1)\n",
    "            # probs = softmax(self.coverage_matrix[expert_to_cover][s1]*10)\n",
    "            idx_to_add = np.random.multinomial(1,probs).argmax()\n",
    "            bisect.insort(rc,anti_state[idx_to_add])\n",
    "            \n",
    "        return rc\n",
    "\n",
    "    def temp_schedule(self,i):\n",
    "        schedule = [(5000,0.5), (15000,0.1), (25000,0.01), (35000,0.005), (45000,self.final_temp)]\n",
    "        if i<schedule[0][0]:\n",
    "            return schedule[0][1]\n",
    "        if i>=schedule[-1][0]:\n",
    "            return schedule[-1][1]\n",
    "        for j in range(len(schedule)):\n",
    "            if i<schedule[j+1][0]:\n",
    "                break\n",
    "        start = schedule[j][0]\n",
    "        end = schedule[j+1][0]\n",
    "        start_val = schedule[j][1]\n",
    "        end_val = schedule[j+1][1]\n",
    "\n",
    "        # if i > 20:\n",
    "        #     return self.final_temp\n",
    "\n",
    "        return ((i-start)/(end-start))*(end_val-start_val)+start_val         \n",
    "\n",
    "    def get_scored_permutations(self, k):\n",
    "        n = len(self.candidates)\n",
    "        return [(x,self.get_score(list(x))) for x in itertools.permutations(range(n),k)]\n",
    "\n",
    "    def reset(self):\n",
    "        return max(self.opt_results,key=lambda x:x[1])[0]\n",
    "    \n",
    "        \n",
    "    def simulated_annealing(self, initial_state, clear_prev = False, reset_every = None):\n",
    "        current_temp = self.initial_temp\n",
    "        i = 0\n",
    "        if clear_prev:\n",
    "            self.opt_results = []\n",
    "        if not reset_every:\n",
    "            reset_every = self.reset_every\n",
    "\n",
    "       # Start by initializing the current state with the initial state\n",
    "        current_state = initial_state\n",
    "        curr_score = self.get_score(initial_state)\n",
    "\n",
    "        while current_temp > self.final_temp:\n",
    "            if i % reset_every == 0 and i>0:                \n",
    "                next_cand = self.reset()\n",
    "                print(\"Reset to state: {}\".format(next_cand))\n",
    "            else:\n",
    "                next_cand = self.get_candidate(current_state)            \n",
    "            next_score = self.get_score(next_cand)\n",
    "\n",
    "            # print(\"current score: {} ({}). Candidate score: {} ({})\".format(curr_score,current_state,next_score,next_cand))\n",
    "\n",
    "            # Check if next_cand is best so far\n",
    "            score_diff = next_score - curr_score\n",
    "\n",
    "            # if the new solution is better, accept it\n",
    "            move = False\n",
    "            if score_diff > 0:\n",
    "                move = True\n",
    "            # if the new solution is not better, accept it with a probability of e^(-cost/temp)\n",
    "            else:\n",
    "                # print(\"chance to move (from score_diff {}): {}\".format(score_diff,math.exp(score_diff / current_temp)))\n",
    "                move = random.uniform(0, 1) < math.exp(score_diff / current_temp)                    \n",
    "            if move:\n",
    "                current_state = next_cand\n",
    "                curr_score = next_score\n",
    "                self.opt_results.append((current_state,curr_score))\n",
    "            # decrement the temperature\n",
    "            current_temp = self.temp_schedule(i)\n",
    "            i += 1\n",
    "            if i % 1000 == 0:\n",
    "                print(\"i: {}\".format(i))            \n",
    "\n",
    "        return self.reset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerset(iterable):\n",
    "    s = list(iterable)\n",
    "    return itertools.chain.from_iterable(itertools.combinations(s, r) for r in range(1,len(s)+1))\n",
    "\n",
    "\n",
    "def optimize_sents(emb_video, experts, sents, compat_scores, use_ordered_scores=False):\n",
    "    smanager = SimilarityManager()\n",
    "    compat_scores = np.array(compat_scores)\n",
    "    as_compat = compat_scores.argsort()\n",
    "    # print(compat_scores)\n",
    "    graded_scores = sorted(list(zip(as_compat,range(len(as_compat)))),key = lambda x:x[0])\n",
    "    # print(list(zip(as_compat,range(len(as_compat)))))\n",
    "    # print(graded_scores)\n",
    "    order_scores = np.array(list(zip(*graded_scores))[1]) / len(graded_scores)\n",
    "    print(order_scores)\n",
    "    # print(list(zip(compat_scores[as_compat],as_compat)))\n",
    "    candidates_similarity = compute_batch_scores(emb_video, sents)\n",
    "    coverage_matrix = np.zeros([len(experts),len(sents)])\n",
    "    coverage_matrix[:] = np.nan\n",
    "    for i in range(len(experts)):\n",
    "        for j in range(len(sents)):\n",
    "            coverage_matrix[i][j]=smanager.similarity(experts[i],sents[j])\n",
    "\n",
    "    def get_score(state: List[int]) -> float:\n",
    "        theta_similarity = 9\n",
    "        theta_coverage = 1\n",
    "        theta_compat = 9\n",
    "        if not state:\n",
    "            return 0\n",
    "        coverage_score = get_state_coverage(state)   \n",
    "        similarity_score = candidates_similarity[state].mean().item()\n",
    "        if use_ordered_scores:            \n",
    "             compat_score = order_scores[state].mean().item()\n",
    "        else:            \n",
    "             compat_score = compat_scores[state].mean().item()\n",
    "        return theta_coverage*coverage_score + theta_similarity*similarity_score + theta_compat*compat_score\n",
    "\n",
    "    def get_expert_coverage(state):\n",
    "        # return self.coverage_matrix[:,state].sum(axis=1)\n",
    "        return coverage_matrix[:,state].max(axis=1)\n",
    "          \n",
    "    def get_state_coverage(state) -> float:\n",
    "        # print(\"State coverage for {}:\".format(state))\n",
    "        # print(get_expert_coverage(state))\n",
    "        return np.mean(get_expert_coverage(state))\n",
    "\n",
    "\n",
    "    superset = list(range(len(sents)))\n",
    "    pset = [list(x) for x in powerset(superset)]\n",
    "    pset_scores = [get_score(x) for x in pset]\n",
    "    best_cand = pset[np.argmax(pset_scores)]\n",
    "    return list(itemgetter(*best_cand)(sents)), candidates_similarity[best_cand].mean()\n",
    "\n",
    "def optimize_scene(doc,mat=None, emb_video=None, **kwargs):\n",
    "    mid = doc['movie_id']\n",
    "    elem = doc['scene_element']\n",
    "    emb_video = clip.clip_encode_video(mid,elem)\n",
    "    all_sents = doc['sentences']\n",
    "    rc = mdb.get_scene_from_collection(mid,elem,'s2_clsmdc')    \n",
    "    experts = flatten(rc['experts'].values())\n",
    "    rc = mdb.get_scene_from_collection(mid,elem,s2_compatibility_collection_name)  \n",
    "    all_compat_scores = rc['compat_scores']\n",
    "    n = len(all_sents)\n",
    "    rc_sents = n*[None]\n",
    "    mean_scores = n*[None]\n",
    "    for i in range(n):\n",
    "        rc_sents[i], mean_scores[i] = optimize_sents(emb_video,experts,all_sents[i],all_compat_scores[i], **kwargs)\n",
    "\n",
    "    return rc_sents, mean_scores\n",
    "    \n",
    "def run_pipeline(all_docs, target_collection_name=s2_with_compat_collection_name, **kwargs):\n",
    "    for doc in all_docs:\n",
    "        mid = doc['movie_id']\n",
    "        elem = doc['scene_element']\n",
    "        rc = mdb.get_scene_from_collection(mid,elem,target_collection_name)\n",
    "        if rc:\n",
    "            print(\"Results already exist for {}/{}\".format(mid,elem))\n",
    "            continue\n",
    "        print(\"Going forward with {}/{}\".format(mid,elem))\n",
    "\n",
    "        rc_sents, sim_scores = optimize_scene(doc,**kwargs)\n",
    "        rc_doc = {\n",
    "            'movie_id': mid,\n",
    "            'scene_element': elem,\n",
    "            'sentences': rc_sents,\n",
    "            'mean_scores': sim_scores,\n",
    "        }\n",
    "        query = \"INSERT {} INTO {}\".format(rc_doc,target_collection_name)\n",
    "        cursor = pipeline.db.aql.execute(query)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'FOR doc IN {} RETURN doc'.format(s2_results_relaxed_collection_name)\n",
    "cursor = pipeline.db.aql.execute(query)\n",
    "all_docs = sorted(list(cursor), key=lambda x:\"{}/{}\".format(x['movie_id'],x['scene_element']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pipeline(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://ec2-18-159-140-240.eu-central-1.compute.amazonaws.com:7000/static/dataset1/concatenated_mp4_200/0026_The_Big_Fish_01.27.55.748-01.28.12.028.mp4\n",
      "24.0\n",
      "Movie info: {'arango_id': 'Movies/222509634', 'source': 'lsmdc', 'fps': 24, 'width': 1920, 'height': 1080, 'scenes': [[0, 542]], 'mdfs': [[3, 317, 517], [523, 534, 538]], 'scene_elements': [[0, 520], [520, 542]]}\n",
      "fn path: /tmp/file.mp4\n",
      "/tmp/file.mp4\n",
      "Scene:  1\n",
      "[0.76923077 0.15384615 0.         0.30769231 0.38461538 0.23076923\n",
      " 0.84615385 0.53846154 0.61538462 0.07692308 0.92307692 0.46153846\n",
      " 0.69230769]\n",
      "[0.         0.07692308 0.23076923 0.30769231 0.46153846 0.38461538\n",
      " 0.69230769 0.84615385 0.61538462 0.15384615 0.76923077 0.92307692\n",
      " 0.53846154]\n",
      "[0.84615385 0.         0.07692308 0.46153846 0.69230769 0.30769231\n",
      " 0.23076923 0.15384615 0.61538462 0.38461538 0.92307692 0.53846154\n",
      " 0.76923077]\n",
      "[0.15384615 0.30769231 0.46153846 0.07692308 0.69230769 0.84615385\n",
      " 0.         0.76923077 0.61538462 0.23076923 0.92307692 0.38461538\n",
      " 0.53846154]\n",
      "[0.76923077 0.46153846 0.07692308 0.         0.23076923 0.61538462\n",
      " 0.53846154 0.92307692 0.69230769 0.15384615 0.30769231 0.38461538\n",
      " 0.84615385]\n",
      "[0.84615385 0.15384615 0.         0.46153846 0.38461538 0.07692308\n",
      " 0.53846154 0.61538462 0.92307692 0.23076923 0.30769231 0.69230769\n",
      " 0.76923077]\n",
      "[0.76923077 0.15384615 0.         0.46153846 0.69230769 0.53846154\n",
      " 0.84615385 0.07692308 0.23076923 0.61538462 0.30769231 0.92307692\n",
      " 0.38461538]\n",
      "[0.76923077 0.61538462 0.30769231 0.46153846 0.07692308 0.53846154\n",
      " 0.23076923 0.84615385 0.38461538 0.         0.15384615 0.92307692\n",
      " 0.69230769]\n",
      "[0.         0.23076923 0.30769231 0.07692308 0.76923077 0.61538462\n",
      " 0.92307692 0.69230769 0.53846154 0.15384615 0.38461538 0.84615385\n",
      " 0.46153846]\n",
      "[0.53846154 0.30769231 0.76923077 0.23076923 0.07692308 0.46153846\n",
      " 0.92307692 0.         0.69230769 0.15384615 0.84615385 0.38461538\n",
      " 0.61538462]\n"
     ]
    }
   ],
   "source": [
    "rc, sim_scores = optimize_scene(all_docs[1])\n",
    "rc1, sim_scores1 = optimize_scene(all_docs[1], use_ordered_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['an old woman with curly hair is watching you in a room',\n",
       "   'A blonde woman in a blue dress is watching another woman with a ring in her hand',\n",
       "   'An old woman in a blue dress is standing in a room and watching you',\n",
       "   'A woman in a blue dress is standing in a room and watches as the door begins to ring'],\n",
       "  ['a blonde woman in a blue dress is watching you starting to talk to you',\n",
       "   'an old woman with curly hair is watching you in a room',\n",
       "   'An old woman with curly hair is watching in a room',\n",
       "   'A blonde woman in a blue dress is watching another woman with a ring in her hand',\n",
       "   'An old woman in a blue dress is standing in a room and watching you',\n",
       "   'a woman with curly hair in a blue dress is watching somebody through the door'],\n",
       "  ['a blonde woman in a blue dress is watching you starting to talk to you',\n",
       "   'an old woman with curly hair is watching you in a room',\n",
       "   'An old woman with curly hair is watching in a room',\n",
       "   'A woman in a blue dress is standing in a room and watches as the door begins to ring'],\n",
       "  ['an old woman with curly hair is watching you in a room',\n",
       "   'An old woman with curly hair is watching in a room',\n",
       "   'A blonde woman in a blue dress is watching another woman with a ring in her hand',\n",
       "   'An old woman in a blue dress is standing in a room and watching you',\n",
       "   'A woman in a blue dress is standing in a room and watches as the door begins to ring'],\n",
       "  ['an old woman with curly hair is watching you in a room',\n",
       "   'a woman with curly hair in a blue dress is looking through the door into a room',\n",
       "   'An old woman with curly hair is watching in a room',\n",
       "   'A blonde woman in a blue dress is watching another woman with a ring in her hand',\n",
       "   'An old woman in a blue dress is standing in a room and watching you'],\n",
       "  ['a blonde woman in a blue dress is watching you starting to talk to you',\n",
       "   'An old woman with curly hair is watching in a room',\n",
       "   'An old woman in a blue dress is standing in a room and watching you',\n",
       "   'A woman in a blue dress is standing in a room and watches as the door begins to ring'],\n",
       "  ['a woman with curly hair in a blue dress is looking through the door into a room',\n",
       "   'An old woman with curly hair is watching in a room',\n",
       "   'A blonde woman in a blue dress is watching another woman with a ring in her hand',\n",
       "   'An old woman in a blue dress is standing in a room and watching you'],\n",
       "  ['a blonde woman in a blue dress is watching you starting to talk to you',\n",
       "   'a woman with curly hair in a blue dress is looking through the door into a room',\n",
       "   'A blonde woman in a blue dress is watching another woman with a ring in her hand',\n",
       "   'An old woman in a blue dress is standing in a room and watching you'],\n",
       "  ['an old woman with curly hair is watching you in a room',\n",
       "   'An old woman with curly hair is watching in a room',\n",
       "   'A woman in a blue dress is standing in a room and watches as the door begins to ring',\n",
       "   'a blonde woman in a blue dress is opening the door and standing in a room'],\n",
       "  ['an old woman with curly hair is watching you in a room',\n",
       "   'An old woman with curly hair is watching in a room',\n",
       "   'A blonde woman in a blue dress is watching another woman with a ring in her hand',\n",
       "   'An old woman in a blue dress is standing in a room and watching you',\n",
       "   'a blonde woman in a blue dress is opening the door and standing in a room']],\n",
       " [0.2292,\n",
       "  0.2295,\n",
       "  0.2296,\n",
       "  0.2301,\n",
       "  0.2303,\n",
       "  0.2312,\n",
       "  0.2303,\n",
       "  0.2307,\n",
       "  0.2257,\n",
       "  0.2299])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc, sim_scores"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dafab0f5b0f2e0b482ce484a64bf4a63ea947b97362cb54784af04b5754b7b41"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
