{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/notebooks/pipenv\")\n",
    "sys.path.insert(0, \"/notebooks/nebula3_vlm\")\n",
    "sys.path.insert(0, \"/notebooks/nebula3_database\")\n",
    "sys.path.insert(0, \"/notebooks/\")\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import bisect\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import urllib\n",
    "import subprocess\n",
    "import re\n",
    "import tempfile\n",
    "import itertools\n",
    "import torch\n",
    "import spacy\n",
    "# import amrlib\n",
    "# import penman\n",
    "\n",
    "from typing import List, Tuple\n",
    "from operator import itemgetter \n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification, BertTokenizer, BertForSequenceClassification\n",
    "from database.arangodb import DatabaseConnector\n",
    "from config import NEBULA_CONF\n",
    "from movie_db import MOVIE_DB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PIPELINE:\n",
    "    def __init__(self):\n",
    "        config = NEBULA_CONF()\n",
    "        self.db_host = config.get_database_host()\n",
    "        self.database = config.get_playground_name()\n",
    "        self.gdb = DatabaseConnector()\n",
    "        self.db = self.gdb.connect_db(self.database)\n",
    "\n",
    "pipeline = PIPELINE()\n",
    "mdb = MOVIE_DB()\n",
    "from vlm.clip_api import CLIP_API\n",
    "clip=CLIP_API('vit')\n",
    "s2_collection_name = 's2_pipeline_after_gpt'\n",
    "s2_results_orig_collection_name = 's2_pipeline_optim_orig'\n",
    "s2_results_relaxed_collection_name = 's2_pipeline_optim_relaxed'\n",
    "s2_compatibility_collection_name = 's2_pipeline_compatibility_scores'\n",
    "s2_with_compat_collection_name = 's2_pipeline_compatibility_results'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(lst): return [x for l in lst for x in l]\n",
    "\n",
    "def compute_batch_scores(video_emb: torch.Tensor, texts: List[str], normalize=True, **kwargs) -> List[float]:    \n",
    "    emb_batch = clip.clip_batch_encode_text(texts, **kwargs)                           \n",
    "    return (video_emb.expand_as(emb_batch)*emb_batch).sum(dim=1).cpu().numpy()\n",
    "\n",
    "\n",
    "def compute_concat_score(image_emb: torch.Tensor, texts: List[str], join_on=',') -> float:\n",
    "    combined_text = \"\"\n",
    "    for t in [x.strip() for x in texts]:\n",
    "        if t[-1]=='.':\n",
    "            t = t[:-1]       \n",
    "        t+=join_on\n",
    "        t+=' '\n",
    "        combined_text+=t\n",
    "    print(\"Combined: \"+combined_text)\n",
    "    return torch.matmul(image_emb,mdmmt.encode_text(combined_text.strip()) )       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def transform_concept(c):\n",
    "#     exp = re.compile(r\"^([a-zA-z]+)-?(\\d*)$\")\n",
    "#     r = exp.match(c)\n",
    "#     return r.group(1) if r else c\n",
    "\n",
    "# class ConceptManager:\n",
    "#     def __init__(self):\n",
    "#         pass\n",
    "#     def ground_concept(concept):\n",
    "#         return transform_concept(concept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimilarityManager:\n",
    "    def __init__(self):\n",
    "        self.nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "    def similarity(self, src, target):\n",
    "        rc = []\n",
    "        s1 = self.nlp(src)\n",
    "        s2 = self.nlp(target)\n",
    "        for w in s1:\n",
    "            # if not w or not w.vector_norm:\n",
    "            #     print('Argghhh 1, bad word:')\n",
    "            #     print(w.text)\n",
    "            if w.pos_ not in ['NOUN', 'ADJ', 'ADV', 'VERB', 'PROPN', 'ADP'] and len(s1)>1:\n",
    "                continue\n",
    "            # for tok in s2:\n",
    "            #     if not tok or not tok.vector_norm:\n",
    "            #         print('Argghhh 2, bad word:')\n",
    "            #         print(tok.text)\n",
    "            #         print(s2.text)\n",
    "            rc.append(max([w.similarity(x) for x in s2]))\n",
    "        return np.mean(rc)\n",
    "        \n",
    "smanager = SimilarityManager()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = lambda x: np.exp(x)/sum(np.exp(x))\n",
    "def normalize(x):\n",
    "    epsilon = 0.00001\n",
    "    if np.std(x) < epsilon:\n",
    "        return np.ones(x.shape)\n",
    "    return (x - np.mean(x)) / np.std(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerset(iterable):\n",
    "    s = list(iterable)\n",
    "    return itertools.chain.from_iterable(itertools.combinations(s, r) for r in range(1,len(s)+1))\n",
    "\n",
    "\n",
    "def optimize_sents(emb_video, experts, sents, compat_scores, use_ordered_scores=False):\n",
    "    smanager = SimilarityManager()\n",
    "    compat_scores = np.array(compat_scores)\n",
    "    as_compat = compat_scores.argsort()\n",
    "    # print(compat_scores)\n",
    "    graded_scores = sorted(list(zip(as_compat,range(len(as_compat)))),key = lambda x:x[0])\n",
    "    # print(list(zip(as_compat,range(len(as_compat)))))\n",
    "    # print(graded_scores)\n",
    "    order_scores = np.array(list(zip(*graded_scores))[1]) / len(graded_scores)\n",
    "    print(order_scores)\n",
    "    # print(list(zip(compat_scores[as_compat],as_compat)))\n",
    "    candidates_similarity = normalize(compute_batch_scores(emb_video, sents))\n",
    "    coverage_matrix = np.zeros([len(experts),len(sents)])\n",
    "    coverage_matrix[:] = np.nan\n",
    "    for i in range(len(experts)):\n",
    "        for j in range(len(sents)):\n",
    "            coverage_matrix[i][j]=smanager.similarity(experts[i],sents[j])\n",
    "        coverage_matrix[i] = normalize(coverage_matrix[i])\n",
    "\n",
    "    def get_score(state: List[int]) -> float:\n",
    "        theta_similarity = 1.\n",
    "        theta_coverage = 1.\n",
    "        theta_compat = 1.\n",
    "        if not state:\n",
    "            return 0\n",
    "        coverage_score = get_state_coverage(state)   \n",
    "        similarity_score = candidates_similarity[state].mean().item()\n",
    "        if use_ordered_scores:            \n",
    "             compat_score = order_scores[state].mean().item()\n",
    "        else:            \n",
    "             compat_score = compat_scores[state].mean().item()\n",
    "        return theta_coverage*coverage_score + theta_similarity*similarity_score + theta_compat*compat_score\n",
    "\n",
    "    def get_expert_coverage(state):\n",
    "        # return self.coverage_matrix[:,state].sum(axis=1)\n",
    "        return coverage_matrix[:,state].max(axis=1)\n",
    "          \n",
    "    def get_state_coverage(state) -> float:\n",
    "        # print(\"State coverage for {}:\".format(state))\n",
    "        # print(get_expert_coverage(state))\n",
    "        return np.mean(get_expert_coverage(state))\n",
    "\n",
    "\n",
    "    superset = list(range(len(sents)))\n",
    "    pset = [list(x) for x in powerset(superset)]\n",
    "    pset_scores = [get_score(x) for x in pset]\n",
    "    best_cand = pset[np.argmax(pset_scores)]\n",
    "    print(\"Best candidates:\")\n",
    "    print(best_cand)\n",
    "    rc = list(itemgetter(*best_cand)(sents)), candidates_similarity[best_cand].mean()\n",
    "    if type(rc)==int:\n",
    "        return [rc]\n",
    "    else:\n",
    "        return rc\n",
    "\n",
    "def optimize_scene(doc,mat=None, emb_video=None, **kwargs):\n",
    "    mid = doc['movie_id']\n",
    "    elem = doc['scene_element']\n",
    "    emb_video = clip.clip_encode_video(mid,elem)\n",
    "    all_sents = doc['sentences']\n",
    "    rc = mdb.get_scene_from_collection(mid,elem,'s2_clsmdc')    \n",
    "    experts = flatten(rc['experts'].values())\n",
    "    rc = mdb.get_scene_from_collection(mid,elem,s2_compatibility_collection_name)  \n",
    "    all_compat_scores = rc['compat_scores']\n",
    "    n = len(all_sents)\n",
    "    rc_sents = n*[None]\n",
    "    mean_scores = n*[None]\n",
    "    for i in range(n):\n",
    "        rc_sents[i], mean_scores[i] = optimize_sents(emb_video,experts,all_sents[i],all_compat_scores[i], **kwargs)\n",
    "\n",
    "    return rc_sents, mean_scores\n",
    "    \n",
    "def run_pipeline(all_docs, target_collection_name=s2_with_compat_collection_name, **kwargs):\n",
    "    for doc in all_docs:\n",
    "        mid = doc['movie_id']\n",
    "        elem = doc['scene_element']\n",
    "        rc = mdb.get_scene_from_collection(mid,elem,target_collection_name)\n",
    "        if rc:\n",
    "            print(\"Results already exist for {}/{}\".format(mid,elem))\n",
    "            continue\n",
    "        print(\"Going forward with {}/{}\".format(mid,elem))\n",
    "\n",
    "        rc_sents, sim_scores = optimize_scene(doc,**kwargs)\n",
    "        rc_doc = {\n",
    "            'movie_id': mid,\n",
    "            'scene_element': elem,\n",
    "            'sentences': rc_sents,\n",
    "            'mean_scores': sim_scores,\n",
    "        }\n",
    "        query = \"INSERT {} INTO {}\".format(rc_doc,target_collection_name)\n",
    "        cursor = pipeline.db.aql.execute(query)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type((3,2))==int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'FOR doc IN {} RETURN doc'.format(s2_results_relaxed_collection_name)\n",
    "cursor = pipeline.db.aql.execute(query)\n",
    "all_docs = sorted(list(cursor), key=lambda x:\"{}/{}\".format(x['movie_id'],x['scene_element']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pipeline(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 4)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten([[itemgetter(*[2,3])([1,2,3,4,5,6,7,8,9])]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://ec2-18-159-140-240.eu-central-1.compute.amazonaws.com:7000/static/dataset1/concatenated_mp4_200/0026_The_Big_Fish_01.27.55.748-01.28.12.028.mp4\n",
      "24.0\n",
      "Movie info: {'arango_id': 'Movies/222509634', 'source': 'lsmdc', 'fps': 24, 'width': 1920, 'height': 1080, 'scenes': [[0, 542]], 'mdfs': [[3, 317, 517], [523, 534, 538]], 'scene_elements': [[0, 520], [520, 542]]}\n",
      "fn path: /tmp/file.mp4\n",
      "/tmp/file.mp4\n",
      "Scene:  1\n",
      "[0.76923077 0.15384615 0.         0.30769231 0.38461538 0.23076923\n",
      " 0.84615385 0.53846154 0.61538462 0.07692308 0.92307692 0.46153846\n",
      " 0.69230769]\n",
      "Best candidates:\n",
      "[10]\n",
      "[0.         0.07692308 0.23076923 0.30769231 0.46153846 0.38461538\n",
      " 0.69230769 0.84615385 0.61538462 0.15384615 0.76923077 0.92307692\n",
      " 0.53846154]\n",
      "Best candidates:\n",
      "[0, 7, 9, 10]\n",
      "[0.84615385 0.         0.07692308 0.46153846 0.69230769 0.30769231\n",
      " 0.23076923 0.15384615 0.61538462 0.38461538 0.92307692 0.53846154\n",
      " 0.76923077]\n",
      "Best candidates:\n",
      "[1, 10]\n",
      "[0.15384615 0.30769231 0.46153846 0.07692308 0.69230769 0.84615385\n",
      " 0.         0.76923077 0.61538462 0.23076923 0.92307692 0.38461538\n",
      " 0.53846154]\n",
      "Best candidates:\n",
      "[7]\n",
      "[0.76923077 0.46153846 0.07692308 0.         0.23076923 0.61538462\n",
      " 0.53846154 0.92307692 0.69230769 0.15384615 0.30769231 0.38461538\n",
      " 0.84615385]\n",
      "Best candidates:\n",
      "[7, 9, 10]\n",
      "[0.84615385 0.15384615 0.         0.46153846 0.38461538 0.07692308\n",
      " 0.53846154 0.61538462 0.92307692 0.23076923 0.30769231 0.69230769\n",
      " 0.76923077]\n",
      "Best candidates:\n",
      "[10]\n",
      "[0.76923077 0.15384615 0.         0.46153846 0.69230769 0.53846154\n",
      " 0.84615385 0.07692308 0.23076923 0.61538462 0.30769231 0.92307692\n",
      " 0.38461538]\n",
      "Best candidates:\n",
      "[8]\n",
      "[0.76923077 0.61538462 0.30769231 0.46153846 0.07692308 0.53846154\n",
      " 0.23076923 0.84615385 0.38461538 0.         0.15384615 0.92307692\n",
      " 0.69230769]\n",
      "Best candidates:\n",
      "[2, 7, 10, 11]\n",
      "[0.         0.23076923 0.30769231 0.07692308 0.76923077 0.61538462\n",
      " 0.92307692 0.69230769 0.53846154 0.15384615 0.38461538 0.84615385\n",
      " 0.46153846]\n",
      "Best candidates:\n",
      "[6]\n",
      "[0.53846154 0.30769231 0.76923077 0.23076923 0.07692308 0.46153846\n",
      " 0.92307692 0.         0.69230769 0.15384615 0.84615385 0.38461538\n",
      " 0.61538462]\n",
      "Best candidates:\n",
      "[6, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "rc, sim_scores = optimize_scene(all_docs[1])\n",
    "# rc1, sim_scores1 = optimize_scene(all_docs[1], use_ordered_scores=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['A',\n",
       "   'n',\n",
       "   ' ',\n",
       "   'o',\n",
       "   'l',\n",
       "   'd',\n",
       "   ' ',\n",
       "   'w',\n",
       "   'o',\n",
       "   'm',\n",
       "   'a',\n",
       "   'n',\n",
       "   ' ',\n",
       "   'i',\n",
       "   'n',\n",
       "   ' ',\n",
       "   'a',\n",
       "   ' ',\n",
       "   'b',\n",
       "   'l',\n",
       "   'u',\n",
       "   'e',\n",
       "   ' ',\n",
       "   'd',\n",
       "   'r',\n",
       "   'e',\n",
       "   's',\n",
       "   's',\n",
       "   ' ',\n",
       "   'i',\n",
       "   's',\n",
       "   ' ',\n",
       "   's',\n",
       "   't',\n",
       "   'a',\n",
       "   'n',\n",
       "   'd',\n",
       "   'i',\n",
       "   'n',\n",
       "   'g',\n",
       "   ' ',\n",
       "   'i',\n",
       "   'n',\n",
       "   ' ',\n",
       "   'a',\n",
       "   ' ',\n",
       "   'r',\n",
       "   'o',\n",
       "   'o',\n",
       "   'm',\n",
       "   ' ',\n",
       "   'a',\n",
       "   'n',\n",
       "   'd',\n",
       "   ' ',\n",
       "   'w',\n",
       "   'a',\n",
       "   't',\n",
       "   'c',\n",
       "   'h',\n",
       "   'i',\n",
       "   'n',\n",
       "   'g',\n",
       "   ' ',\n",
       "   'y',\n",
       "   'o',\n",
       "   'u'],\n",
       "  ['a blonde woman in a blue dress is watching you starting to talk to you',\n",
       "   'An old woman with curly hair is watching in a room',\n",
       "   'A blonde woman in a blue dress is watching another woman with a ring in her hand',\n",
       "   'An old woman in a blue dress is standing in a room and watching you'],\n",
       "  ['a blonde woman in a blue dress is watching you starting to talk to you',\n",
       "   'An old woman with curly hair is watching in a room'],\n",
       "  ['A',\n",
       "   'n',\n",
       "   ' ',\n",
       "   'o',\n",
       "   'l',\n",
       "   'd',\n",
       "   ' ',\n",
       "   'w',\n",
       "   'o',\n",
       "   'm',\n",
       "   'a',\n",
       "   'n',\n",
       "   ' ',\n",
       "   'i',\n",
       "   'n',\n",
       "   ' ',\n",
       "   'a',\n",
       "   ' ',\n",
       "   'b',\n",
       "   'l',\n",
       "   'u',\n",
       "   'e',\n",
       "   ' ',\n",
       "   'd',\n",
       "   'r',\n",
       "   'e',\n",
       "   's',\n",
       "   's',\n",
       "   ' ',\n",
       "   'i',\n",
       "   's',\n",
       "   ' ',\n",
       "   's',\n",
       "   't',\n",
       "   'a',\n",
       "   'n',\n",
       "   'd',\n",
       "   'i',\n",
       "   'n',\n",
       "   'g',\n",
       "   ' ',\n",
       "   'i',\n",
       "   'n',\n",
       "   ' ',\n",
       "   'a',\n",
       "   ' ',\n",
       "   'r',\n",
       "   'o',\n",
       "   'o',\n",
       "   'm',\n",
       "   ' ',\n",
       "   'a',\n",
       "   'n',\n",
       "   'd',\n",
       "   ' ',\n",
       "   'w',\n",
       "   'a',\n",
       "   't',\n",
       "   'c',\n",
       "   'h',\n",
       "   'i',\n",
       "   'n',\n",
       "   'g',\n",
       "   ' ',\n",
       "   'y',\n",
       "   'o',\n",
       "   'u'],\n",
       "  ['An old woman with curly hair is watching in a room',\n",
       "   'A blonde woman in a blue dress is watching another woman with a ring in her hand',\n",
       "   'An old woman in a blue dress is standing in a room and watching you'],\n",
       "  ['A',\n",
       "   'n',\n",
       "   ' ',\n",
       "   'o',\n",
       "   'l',\n",
       "   'd',\n",
       "   ' ',\n",
       "   'w',\n",
       "   'o',\n",
       "   'm',\n",
       "   'a',\n",
       "   'n',\n",
       "   ' ',\n",
       "   'i',\n",
       "   'n',\n",
       "   ' ',\n",
       "   'a',\n",
       "   ' ',\n",
       "   'b',\n",
       "   'l',\n",
       "   'u',\n",
       "   'e',\n",
       "   ' ',\n",
       "   'd',\n",
       "   'r',\n",
       "   'e',\n",
       "   's',\n",
       "   's',\n",
       "   ' ',\n",
       "   'i',\n",
       "   's',\n",
       "   ' ',\n",
       "   's',\n",
       "   't',\n",
       "   'a',\n",
       "   'n',\n",
       "   'd',\n",
       "   'i',\n",
       "   'n',\n",
       "   'g',\n",
       "   ' ',\n",
       "   'i',\n",
       "   'n',\n",
       "   ' ',\n",
       "   'a',\n",
       "   ' ',\n",
       "   'r',\n",
       "   'o',\n",
       "   'o',\n",
       "   'm',\n",
       "   ' ',\n",
       "   'a',\n",
       "   'n',\n",
       "   'd',\n",
       "   ' ',\n",
       "   'w',\n",
       "   'a',\n",
       "   't',\n",
       "   'c',\n",
       "   'h',\n",
       "   'i',\n",
       "   'n',\n",
       "   'g',\n",
       "   ' ',\n",
       "   'y',\n",
       "   'o',\n",
       "   'u'],\n",
       "  ['A',\n",
       "   'n',\n",
       "   ' ',\n",
       "   'o',\n",
       "   'l',\n",
       "   'd',\n",
       "   ' ',\n",
       "   'w',\n",
       "   'o',\n",
       "   'm',\n",
       "   'a',\n",
       "   'n',\n",
       "   ' ',\n",
       "   'i',\n",
       "   'n',\n",
       "   ' ',\n",
       "   'a',\n",
       "   ' ',\n",
       "   'b',\n",
       "   'l',\n",
       "   'u',\n",
       "   'e',\n",
       "   ' ',\n",
       "   'd',\n",
       "   'r',\n",
       "   'e',\n",
       "   's',\n",
       "   's',\n",
       "   ' ',\n",
       "   'i',\n",
       "   's',\n",
       "   ' ',\n",
       "   's',\n",
       "   't',\n",
       "   'a',\n",
       "   'n',\n",
       "   'd',\n",
       "   'i',\n",
       "   'n',\n",
       "   'g',\n",
       "   ' ',\n",
       "   'i',\n",
       "   'n',\n",
       "   ' ',\n",
       "   'a',\n",
       "   ' ',\n",
       "   'r',\n",
       "   'o',\n",
       "   'o',\n",
       "   'm',\n",
       "   ' ',\n",
       "   'a',\n",
       "   'n',\n",
       "   'd',\n",
       "   ' ',\n",
       "   'w',\n",
       "   'a',\n",
       "   't',\n",
       "   'c',\n",
       "   'h',\n",
       "   'i',\n",
       "   'n',\n",
       "   'g',\n",
       "   ' ',\n",
       "   'y',\n",
       "   'o',\n",
       "   'u'],\n",
       "  ['a blonde woman in a blue dress is watching you starting to talk to you',\n",
       "   'an old woman with curly hair is watching you in a room',\n",
       "   'A blonde woman in a blue dress is watching another woman with a ring in her hand',\n",
       "   'An old woman in a blue dress is standing in a room and watching you'],\n",
       "  ['A',\n",
       "   'n',\n",
       "   ' ',\n",
       "   'o',\n",
       "   'l',\n",
       "   'd',\n",
       "   ' ',\n",
       "   'w',\n",
       "   'o',\n",
       "   'm',\n",
       "   'a',\n",
       "   'n',\n",
       "   ' ',\n",
       "   'w',\n",
       "   'i',\n",
       "   't',\n",
       "   'h',\n",
       "   ' ',\n",
       "   'c',\n",
       "   'u',\n",
       "   'r',\n",
       "   'l',\n",
       "   'y',\n",
       "   ' ',\n",
       "   'h',\n",
       "   'a',\n",
       "   'i',\n",
       "   'r',\n",
       "   ' ',\n",
       "   'i',\n",
       "   's',\n",
       "   ' ',\n",
       "   'w',\n",
       "   'a',\n",
       "   't',\n",
       "   'c',\n",
       "   'h',\n",
       "   'i',\n",
       "   'n',\n",
       "   'g',\n",
       "   ' ',\n",
       "   'i',\n",
       "   'n',\n",
       "   ' ',\n",
       "   'a',\n",
       "   ' ',\n",
       "   'r',\n",
       "   'o',\n",
       "   'o',\n",
       "   'm'],\n",
       "  ['An old woman with curly hair is watching in a room',\n",
       "   'A blonde woman in a blue dress is watching another woman with a ring in her hand',\n",
       "   'An old woman in a blue dress is standing in a room and watching you']],\n",
       " [1.65, 1.007, 1.604, 1.563, 1.258, 1.545, 1.909, 1.109, 1.881, 1.175])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc, sim_scores"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dafab0f5b0f2e0b482ce484a64bf4a63ea947b97362cb54784af04b5754b7b41"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
