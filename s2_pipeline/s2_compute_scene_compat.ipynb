{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/notebooks/pipenv\")\n",
    "sys.path.insert(0, \"/notebooks/nebula3_vlm\")\n",
    "sys.path.insert(0, \"/notebooks/nebula3_database\")\n",
    "sys.path.insert(0, \"/notebooks/\")\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import bisect\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import urllib\n",
    "import subprocess\n",
    "import re\n",
    "import tempfile\n",
    "import itertools\n",
    "import torch\n",
    "import spacy\n",
    "from torch.nn.functional import softmax as torch_softmax\n",
    "from sumproduct import Variable, Factor, FactorGraph\n",
    "\n",
    "from typing import List, Tuple\n",
    "from operator import itemgetter \n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification, BertTokenizer, BertForNextSentencePrediction\n",
    "from database.arangodb import DatabaseConnector\n",
    "from config import NEBULA_CONF\n",
    "from movie_db import MOVIE_DB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PIPELINE:\n",
    "    def __init__(self):\n",
    "        config = NEBULA_CONF()\n",
    "        self.db_host = config.get_database_host()\n",
    "        self.database = config.get_playground_name()\n",
    "        self.gdb = DatabaseConnector()\n",
    "        self.db = self.gdb.connect_db(self.database)\n",
    "\n",
    "pipeline = PIPELINE()\n",
    "mdb = MOVIE_DB()\n",
    "from vlm.clip_api import CLIP_API\n",
    "clip=CLIP_API('vit')\n",
    "s2_collection_name = 's2_pipeline_after_gpt'\n",
    "s2_results_orig_collection_name = 's2_pipeline_optim_orig'\n",
    "s2_results_relaxed_collection_name = 's2_pipeline_optim_relaxed'\n",
    "s2_compatibility_collection_name = 's2_pipeline_compatibility_scores'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForNextSentencePrediction.from_pretrained('bert-base-uncased')\n",
    "device = \"cuda:0\"\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_2chain_graph(factors):\n",
    "    g = FactorGraph(silent=True)  # init the graph without message printouts\n",
    "    num_vars = len(factors)+1\n",
    "    vars = []\n",
    "    vnames = []\n",
    "    gvars = []\n",
    "    for i in range(len(factors)-1):\n",
    "        assert factors[i].shape[1] == factors[i+1].shape[0]\n",
    "        vars.append(factors[i].shape[0])\n",
    "    vars.append(factors[-1].shape[0])\n",
    "    vars.append(factors[-1].shape[1])\n",
    "    for i, v_size in enumerate(vars):\n",
    "        vname = 'x'+str(i+1)\n",
    "        v = Variable(vname, v_size)\n",
    "        vnames.append(vname)\n",
    "        gvars.append(v)\n",
    "\n",
    "    for i in range(len(gvars)-1):\n",
    "        fname = 'f{}{}'.format(i+1, i+2)\n",
    "        # factors are transposed, from x2 to x1, etc'\n",
    "        fact = Factor(fname, factors[i].transpose())\n",
    "        g.add(fact)\n",
    "        g.append(fname, gvars[i+1])\n",
    "        g.append(fname, gvars[i])\n",
    "\n",
    "    return g, vnames\n",
    "\n",
    "\n",
    "def create_3chain_graph(factors):\n",
    "    g = FactorGraph(silent=True)  # init the graph without message printouts\n",
    "    num_vars = len(factors)+2\n",
    "    vars = []\n",
    "    vnames = []\n",
    "    gvars = []\n",
    "    for i in range(len(factors)-2):\n",
    "        assert factors[i].shape[1] == factors[i+1].shape[0]\n",
    "        assert factors[i].shape[2] == factors[i+1].shape[1]\n",
    "        assert factors[i].shape[2] == factors[i+2].shape[0]\n",
    "        vars.append(factors[i].shape[0])\n",
    "    vars.append(factors[-2].shape[0])\n",
    "    vars.append(factors[-2].shape[1])\n",
    "    vars.append(factors[-2].shape[2])\n",
    "    vars.append(factors[-1].shape[2])\n",
    "    for i, n in enumerate(vars):\n",
    "        vname = 'x'+str(i+1)\n",
    "        v = Variable(vname, n)\n",
    "        vnames.append(vname)\n",
    "        gvars.append(v)\n",
    "    for i in range(len(gvars)-2):\n",
    "        fname = 'f{}{}{}'.format(i+1, i+2, i+3)\n",
    "        fact = Factor(fname, factors[i].transpose(\n",
    "            2, 1, 0))     # factors are transposed\n",
    "        g.add(fact)\n",
    "        g.append(fname, gvars[i+2])\n",
    "        g.append(fname, gvars[i+1])\n",
    "        g.append(fname, gvars[i])\n",
    "\n",
    "    return g, vnames\n",
    "\n",
    "def compute_marginals(factors, chain_creator):\n",
    "    g, vnames = chain_creator(factors)\n",
    "    g.compute_marginals(max_iter=15500, tolerance=1e-8)\n",
    "    rc = []\n",
    "    for vname in vnames:\n",
    "        rc.append(g.nodes[vname].marginal())\n",
    "    return rc\n",
    "\n",
    "def compute_2chain_marginals(factors):\n",
    "    return compute_marginals(factors, create_2chain_graph)\n",
    "\n",
    "\n",
    "def compute_3chain_marginals(factors):\n",
    "    return compute_marginals(factors, create_3chain_graph)\n",
    "\n",
    "# def compute_2chain_marginals_orig(factors):\n",
    "#     g, vnames = create_2chain_graph(factors)\n",
    "#     g.compute_marginals(max_iter=15500, tolerance=1e-8)\n",
    "#     rc = []\n",
    "#     for vname in vnames:\n",
    "#         rc.append(g.nodes[vname].marginal())\n",
    "#     return rc\n",
    "\n",
    "# Input: A list of list of strings\n",
    "# Output: A list of list of scores\n",
    "\n",
    "def story_compatability(scene1, scene2):\n",
    "    rows_ = []\n",
    "    for sent_a in scene1:\n",
    "        cols_ = []\n",
    "        for sent_b in scene2:\n",
    "            encoded = tokenizer.encode_plus(sent_a, sent_b, return_tensors='pt').to(device)\n",
    "            seq_relationship_logits = model(**encoded)[0]\n",
    "            probs = torch_softmax(seq_relationship_logits, dim=1)\n",
    "            score = probs[0][0].tolist()\n",
    "            cols_.append(score)\n",
    "        rows_.append(cols_)\n",
    "    return(np.array(rows_))\n",
    "\n",
    "\n",
    "def score_story(story):\n",
    "    scenes_scores = []\n",
    "    for idx in range(0, len(story) -1):\n",
    "        scene1 = story[idx]\n",
    "        scene2 = story[idx + 1]\n",
    "        scene_matrix = story_compatability(scene1, scene2)\n",
    "        scenes_scores.append(scene_matrix)\n",
    "\n",
    "    return scenes_scores\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda lst: [x for l in lst for x in l]\n",
    "softmax = lambda x: np.exp(x)/sum(np.exp(x))\n",
    "normalize = lambda x: (x - np.mean(x)) / np.std(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'FOR doc IN {} RETURN doc'.format(s2_results_orig_collection_name)\n",
    "cursor = pipeline.db.aql.execute(query)\n",
    "all_docs = list(cursor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = set([x['movie_id'] for x in all_docs])\n",
    "all_movies = {}\n",
    "\n",
    "for mid in movies:\n",
    "    story = []\n",
    "    elements = sorted([x for x in all_docs if x['movie_id'] == mid],key=lambda y:y['scene_element'])\n",
    "    all_movies[mid] = elements\n",
    "    # n = len(elements[0]['sentences'])    # Number of copies\n",
    "    # for i in range(n):\n",
    "    #     story=[elem['sentences'][i] for elem in elements]\n",
    "    #     for (elem,story_part) in zip(elements,story):\n",
    "    #         elem['sentences'][i]=zip(elem['sentences'][i],story[i])     # Update scene_element with scores\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "story_obj = all_movies[list(all_movies.keys())[0]]\n",
    "story = [x['sentences'][0] for x in story_obj]\n",
    "rc = score_story(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(story[0])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dafab0f5b0f2e0b482ce484a64bf4a63ea947b97362cb54784af04b5754b7b41"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('nebula')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
