{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/notebooks/pipenv\")\n",
    "sys.path.insert(0, \"/notebooks/nebula3_database\")\n",
    "sys.path.insert(0, \"/notebooks/nebula3_experiments\")\n",
    "sys.path.insert(0, \"/notebooks/nebula3_videoprocessing\")\n",
    "sys.path.insert(0, \"/notebooks/\")\n",
    "from PIL import Image\n",
    "import requests\n",
    "import visual_genome.local as vg\n",
    "import json\n",
    "import copy\n",
    "import operator\n",
    "import itertools\n",
    "import subprocess\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import spacy\n",
    "import nltk\n",
    "import openai\n",
    "from spacy_wordnet.wordnet_annotator import WordnetAnnotator \n",
    "from sentence_transformers import SentenceTransformer\n",
    "from database.arangodb import DatabaseConnector\n",
    "from config import NEBULA_CONF\n",
    "from vg_eval import VGEvaluation, get_sc_graph, spice_get_triplets, tuples_from_sg\n",
    "from videoprocessing.vlm_factory import VlmFactory\n",
    "from videoprocessing.vlm_interface import VlmInterface\n",
    "from videoprocessing.vlm_implementation import VlmChunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "# nlp.add_pipe(\"spacy_wordnet\", after='tagger', config={'lang': nlp.lang})\n",
    "\n",
    "with open('/storage/keys/openai.key','r') as f:\n",
    "    OPENAI_API_KEY = f.readline().strip()\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "VG_DATA = '/storage/vg_data'\n",
    "IPC_COLLECTION = 'ipc_relations_spice'\n",
    "RECALL_COLLECTION = 'ipc_recall_spice'\n",
    "GLOBAL_TOKENS_COLLECTION = 's3_global_tokens'\n",
    "FS_GPT_MODEL = 'text-davinci-002'\n",
    "class PIPELINE:\n",
    "    def __init__(self):\n",
    "        config = NEBULA_CONF()\n",
    "        self.db_host = config.get_database_host()\n",
    "        self.database = config.get_playground_name()\n",
    "        self.gdb = DatabaseConnector()\n",
    "        self.db = self.gdb.connect_db(self.database)\n",
    "pipeline = PIPELINE()\n",
    "def get_all_s3_ids():\n",
    "    results = {}\n",
    "    query = 'FOR doc IN {} RETURN doc.image_id'.format(GLOBAL_TOKENS_COLLECTION)\n",
    "    cursor = pipeline.db.aql.execute(query)\n",
    "    return [doc for doc in cursor]\n",
    "\n",
    "s3_ids = get_all_s3_ids()\n",
    "evaluator = VGEvaluation()\n",
    "def flatten(lst): return [x for l in lst for x in l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GTBaseGenerator:\n",
    "    def __init__(self):\n",
    "        self.pipeline = PIPELINE()\n",
    "        self.ipc_data = json.load(open('/storage/ipc_data/paragraphs_v1.json','r'))\n",
    "        self.global_captioner = 'blip'\n",
    "        self.global_tagger = 'blip'\n",
    "        self.places_source = 'blip'\n",
    "        self.global_prompt1 = '''Caption of image: {}\n",
    "This image is taking place in: {}\n",
    "Tags: This image is about {}\n",
    "Describe this image in detail:'''\n",
    "\n",
    "    def get_image_id_from_collection(self, id,collection=GLOBAL_TOKENS_COLLECTION):\n",
    "        results = {}\n",
    "        query = 'FOR doc IN {} FILTER doc.image_id == {} RETURN doc'.format(collection,id)\n",
    "        cursor = self.pipeline.db.aql.execute(query)\n",
    "        for doc in cursor:\n",
    "            results.update(doc)\n",
    "        return results\n",
    "    \n",
    "    def get_structure(self, id):\n",
    "        sg = get_sc_graph(id)\n",
    "        global_doc = self.get_image_id_from_collection(id)\n",
    "        if not global_doc:\n",
    "            print(\"Couldn't find global tokens for id {}\".format(id))\n",
    "            return\n",
    "        rc_doc = {\n",
    "            'image_id': id,\n",
    "            'url': sg.image.url            \n",
    "        }\n",
    "        for (k,v) in global_doc.items():\n",
    "            if k.startswith('global'):\n",
    "                rc_doc[k]=copy.copy(v)\n",
    "        rois = []\n",
    "        for obj in sg.objects:\n",
    "            obj_dic = {\n",
    "                'GT': list(zip(obj.names,[1.0]*len(obj.names)))\n",
    "            }\n",
    "            attr_dic = {\n",
    "                'GT': list(zip(obj.attributes,[1.0]*len(obj.attributes)))\n",
    "            }\n",
    "            obj_doc = {                \n",
    "                'objects': obj.names,\n",
    "                'attributes': obj.attributes,\n",
    "                'bbox': [obj.x, obj.y, obj.x+obj.width, obj.y+obj.height]              \n",
    "                }\n",
    "            rois.append(obj_doc)\n",
    "        rc_doc['rois']=rois\n",
    "\n",
    "        return rc_doc\n",
    "\n",
    "    def get_prompt(self, id, include_answer=False):\n",
    "        base_doc = self.get_structure(id)\n",
    "        if base_doc == None:\n",
    "            return\n",
    "        caption = base_doc['global_captions'][self.global_captioner]\n",
    "        all_objects = base_doc['global_objects'][self.global_tagger]\n",
    "        all_persons = base_doc['global_persons'][self.global_tagger]\n",
    "        all_places = base_doc['global_scenes'][self.places_source]\n",
    "        # print(\"Caption: {}\".format(caption))\n",
    "        # print(\"Objects: \")\n",
    "        # print(all_objects[:5])\n",
    "        # print(\"Places:\")\n",
    "        # print(all_places[:5])\n",
    "        # print(\"Persons:\")\n",
    "        # print(all_persons[:5])\n",
    "        objects = '; '.join([x['label'] for x in all_objects[:8]])\n",
    "        persons = '; '.join([x['label'] for x in all_persons[:5]])\n",
    "        places = ' or '.join([x['label'] for x in all_places[:3]])\n",
    "        prompt_before_answer = self.global_prompt1.format(caption,places,objects)\n",
    "        if include_answer:\n",
    "            [answer] = [x['paragraph'] for x in self.ipc_data if x['image_id']==id]\n",
    "            final_prompt = prompt_before_answer+\" \"+answer\n",
    "        else:\n",
    "            final_prompt = prompt_before_answer\n",
    "        return final_prompt\n",
    "        \n",
    "base_gen = GTBaseGenerator()\n",
    "\n",
    "def few_shot_process_target_id(fs_ids: list[int],target_id: int, vlm: VlmInterface, pgen=base_gen, **kwargs):\n",
    "    target_sg = get_sc_graph(target_id)\n",
    "    fs_prompt = generate_gpt_prompt(fs_ids, target_id=target_id, pgen=pgen)\n",
    "    results = gpt_execute(fs_prompt, model=FS_GPT_MODEL, **kwargs)\n",
    "    return results\n",
    "    # scores = vlm.compute_similarity_url(target_sg.image.url,results)\n",
    "    # best_index = np.argmax(scores)\n",
    "    # return results[best_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_execute(prompt_template, *args, **kwargs):            \n",
    "    prompt = prompt_template.format(*args)   \n",
    "    response = openai.Completion.create(prompt=prompt, max_tokens=256, **kwargs)   \n",
    "    # return response\n",
    "    return [x['text'].strip() for x in response['choices']]\n",
    "\n",
    "def generate_gpt_prompt(ids, target_id=None, pgen=GTBaseGenerator()):\n",
    "    rc = []\n",
    "    for id in ids:\n",
    "        rc.append(pgen.get_prompt(id,include_answer=True))\n",
    "    if target_id:\n",
    "        rc.append(pgen.get_prompt(target_id,include_answer=False))\n",
    "        print(\"Target id is: {}\".format(target_id))\n",
    "    return '\\n'.join(rc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def candidates_from_paragraph(paragraph):\n",
    "    senter = nlp.get_pipe(\"senter\")\n",
    "    sentences = [str(x) for x in senter(nlp(paragraph)).sents]\n",
    "    n = len(sentences)\n",
    "    cands = []\n",
    "    for i in range(2,n+1):\n",
    "        for comb in itertools.combinations(range(n),i):\n",
    "            cands.append(' '.join(operator.itemgetter(*comb)(sentences)))\n",
    "    return cands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model on GPU\n",
      "load checkpoint from https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large_retrieval_coco.pth\n"
     ]
    }
   ],
   "source": [
    "vlm = VlmChunker(VlmFactory().get_vlm(\"blip_itc\"), chunk_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_train, s3_test = np.split(np.array(s3_ids),[900])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target id is: 2404490\n"
     ]
    }
   ],
   "source": [
    "train_ids = np.random.choice(s3_train,5)\n",
    "target_id = np.random.choice(s3_test)\n",
    "# rc = generate_gpt_prompt(train_ids, target_id=target_id, pgen=base_gen)\n",
    "rc = few_shot_process_target_id(train_ids,target_id,vlm,n=5)\n",
    "candidates = flatten([candidates_from_paragraph(x) for x in rc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A counter with a wine bottle and a wine glass on it. The wine bottle is red and has a gold label on it. The label has black text on it. The wine glass is clear and has a stem. The stem is thin and has a small base. There is liquid in the glass. The liquid is red.',\n",
       " 'A clear, wine bottle with a green label that reads Mouton Cadet 2014 - Bordeaux, France. There is a red wax seal over the cork. The wine glass is next to the bottle and is also clear. It is slightly taller than the bottle and has a stem. The glass is empty.',\n",
       " 'There is a brown counter with a light colored granite counter top. There is a white bottle of wine on the counter with a glass of wine next to it. The cork is still in the bottle of wine. The glass of wine is half full. There is a label on the wine bottle. The label is gold and has black text.',\n",
       " 'There is a dark wood counter. On the counter there is a wine bottle and a wine glass. The wine bottle is clasped with a silver colored ring. The wine glass is filled halfway with red wine. There are small water beads on the outside of the wine glass. On the counter there are also three lemons. Two of the lemons are cut in half.',\n",
       " 'A clear glass bottle of red wine is on the counter. Next to it is a glass of wine. The wine in the glass is red. The label on the bottle is green and white. The cork is in the bottle.']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://cs.stanford.edu/people/rak248/VG_100K_2/2404490.jpg\n"
     ]
    }
   ],
   "source": [
    "sg = get_sc_graph(target_id)\n",
    "print(sg.image.url)\n",
    "scores = vlm.compute_similarity_url(sg.image.url,candidates)\n",
    "# scores = vlm.compute_similarity_url(sg.image.url,[rc[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'On the counter there is a wine bottle and a wine glass. The wine glass is filled halfway with red wine.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates[np.argmax(scores)]\n",
    "# rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [str(x) for x in sentences.sents]\n",
    "cands = []\n",
    "for i in range(len(sentences)):\n",
    "    c = copy.copy(sentences)\n",
    "    c.pop(i)\n",
    "    cands.append(' '.join(c))\n",
    "# vlm.compute_similarity_url(sg.image.url,' '.join(sentences[:-1]))\n",
    "vlm.compute_similarity_url(sg.image.url,cands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2_urls():\n",
    "    [id1, id2] = np.random.choice(s3_ids,2)\n",
    "    sg1 = get_sc_graph(id1)\n",
    "    sg2 = get_sc_graph(id2)\n",
    "    print(sg1.image.url)\n",
    "    print(sg2.image.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg = get_sc_graph(target_id)\n",
    "print(sg.image.url)\n",
    "gt_triplets = tuples_from_sg(sg)\n",
    "pred_triplets = spice_get_triplets(gpt_rc[0])\n",
    "recall = evaluator.recall_triplets_mean(gt_triplets,pred_triplets)\n",
    "print(\"Mean (bert-based) total recall of ground truth triplets in ipc triplets is: {}\".format(recall))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg = get_sc_graph(2359808)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(x.x, x.y, x.x+x.width, x.y+x.height) for x in sg.objects if x.width>=50 and x.height>=50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = senter(nlp(\"Hello world. Hello world again.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(rc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dafab0f5b0f2e0b482ce484a64bf4a63ea947b97362cb54784af04b5754b7b41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
