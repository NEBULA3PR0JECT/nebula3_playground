{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/notebooks/pipenv\")\n",
    "sys.path.insert(0, \"/notebooks/nebula3_database\")\n",
    "sys.path.insert(0, \"/notebooks/nebula3_experiments\")\n",
    "sys.path.insert(0, \"/notebooks/nebula3_videoprocessing\")\n",
    "sys.path.insert(0, \"/notebooks/\")\n",
    "from PIL import Image\n",
    "import requests\n",
    "import visual_genome.local as vg\n",
    "import json\n",
    "import copy\n",
    "import subprocess\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import spacy\n",
    "import nltk\n",
    "import openai\n",
    "from spacy_wordnet.wordnet_annotator import WordnetAnnotator \n",
    "from sentence_transformers import SentenceTransformer\n",
    "from database.arangodb import DatabaseConnector\n",
    "from config import NEBULA_CONF\n",
    "from vg_eval import VGEvaluation, get_sc_graph, spice_get_triplets, tuples_from_sg\n",
    "from videoprocessing.vlm_factory import VlmFactory\n",
    "from videoprocessing.vlm_interface import VlmInterface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "nlp.add_pipe(\"spacy_wordnet\", after='tagger', config={'lang': nlp.lang})\n",
    "\n",
    "with open('/storage/keys/openai.key','r') as f:\n",
    "    OPENAI_API_KEY = f.readline().strip()\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "VG_DATA = '/storage/vg_data'\n",
    "IPC_COLLECTION = 'ipc_relations_spice'\n",
    "RECALL_COLLECTION = 'ipc_recall_spice'\n",
    "GLOBAL_TOKENS_COLLECTION = 's3_global_tokens'\n",
    "FS_GPT_MODEL = 'text-davinci-002'\n",
    "\n",
    "class PIPELINE:\n",
    "    def __init__(self):\n",
    "        config = NEBULA_CONF()\n",
    "        self.db_host = config.get_database_host()\n",
    "        self.database = config.get_playground_name()\n",
    "        self.gdb = DatabaseConnector()\n",
    "        self.db = self.gdb.connect_db(self.database)\n",
    "pipeline = PIPELINE()\n",
    "\n",
    "def get_all_s3_ids():\n",
    "    results = {}\n",
    "    query = 'FOR doc IN {} RETURN doc.image_id'.format(GLOBAL_TOKENS_COLLECTION)\n",
    "    cursor = pipeline.db.aql.execute(query)\n",
    "    return [doc for doc in cursor]\n",
    "\n",
    "s3_ids = get_all_s3_ids()\n",
    "evaluator = VGEvaluation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GTBaseGenerator:\n",
    "    def __init__(self):\n",
    "        self.pipeline = PIPELINE()\n",
    "        self.ipc_data = json.load(open('/storage/ipc_data/paragraphs_v1.json','r'))\n",
    "        self.global_captioner = 'blip'\n",
    "        self.global_tagger = 'blip'\n",
    "        self.places_source = 'blip'\n",
    "        self.global_prompt1 = '''Caption of image: {}\n",
    "This image is taking place in: {}\n",
    "Tags: This image is about {}\n",
    "Describe this image in detail:'''\n",
    "\n",
    "    def get_image_id_from_collection(self, id,collection=GLOBAL_TOKENS_COLLECTION):\n",
    "        results = {}\n",
    "        query = 'FOR doc IN {} FILTER doc.image_id == {} RETURN doc'.format(collection,id)\n",
    "        cursor = self.pipeline.db.aql.execute(query)\n",
    "        for doc in cursor:\n",
    "            results.update(doc)\n",
    "        return results\n",
    "    \n",
    "    def get_structure(self, id):\n",
    "        sg = get_sc_graph(id)\n",
    "        global_doc = self.get_image_id_from_collection(id)\n",
    "        if not global_doc:\n",
    "            print(\"Couldn't find global tokens for id {}\".format(id))\n",
    "            return\n",
    "        rc_doc = {\n",
    "            'image_id': id,\n",
    "            'url': sg.image.url            \n",
    "        }\n",
    "        for (k,v) in global_doc.items():\n",
    "            if k.startswith('global'):\n",
    "                rc_doc[k]=copy.copy(v)\n",
    "        rois = []\n",
    "        for obj in sg.objects:\n",
    "            obj_dic = {\n",
    "                'GT': list(zip(obj.names,[1.0]*len(obj.names)))\n",
    "            }\n",
    "            attr_dic = {\n",
    "                'GT': list(zip(obj.attributes,[1.0]*len(obj.attributes)))\n",
    "            }\n",
    "            obj_doc = {                \n",
    "                'objects': obj.names,\n",
    "                'attributes': obj.attributes,\n",
    "                'bbox': [obj.x, obj.y, obj.x+obj.width, obj.y+obj.height]              \n",
    "                }\n",
    "            rois.append(obj_doc)\n",
    "        rc_doc['rois']=rois\n",
    "\n",
    "        return rc_doc\n",
    "\n",
    "    def get_prompt(self, id, include_answer=False):\n",
    "        base_doc = self.get_structure(id)\n",
    "        if base_doc == None:\n",
    "            return\n",
    "        caption = base_doc['global_captions'][self.global_captioner]\n",
    "        all_objects = base_doc['global_objects'][self.global_tagger]\n",
    "        all_persons = base_doc['global_persons'][self.global_tagger]\n",
    "        all_places = base_doc['global_scenes'][self.places_source]\n",
    "        # print(\"Caption: {}\".format(caption))\n",
    "        # print(\"Objects: \")\n",
    "        # print(all_objects[:5])\n",
    "        # print(\"Places:\")\n",
    "        # print(all_places[:5])\n",
    "        # print(\"Persons:\")\n",
    "        # print(all_persons[:5])\n",
    "        objects = '; '.join([x['label'] for x in all_objects[:8]])\n",
    "        persons = '; '.join([x['label'] for x in all_persons[:5]])\n",
    "        places = ' or '.join([x['label'] for x in all_places[:3]])\n",
    "        prompt_before_answer = self.global_prompt1.format(caption,places,objects)\n",
    "        if include_answer:\n",
    "            [answer] = [x['paragraph'] for x in self.ipc_data if x['image_id']==id]\n",
    "            final_prompt = prompt_before_answer+\" \"+answer\n",
    "        else:\n",
    "            final_prompt = prompt_before_answer\n",
    "        return final_prompt\n",
    "        \n",
    "base_gen = GTBaseGenerator()\n",
    "\n",
    "def few_shot_process_target_id(fs_ids: list[int],target_id: list[int], vlm: VlmInterface, pgen=base_gen, **kwargs):\n",
    "    target_sg = get_sc_graph(target_id)\n",
    "    fs_prompt = generate_gpt_prompt(fs_ids, target_id=target_id, pgen=pgen)\n",
    "    results = gpt_execute(fs_prompt, model=FS_GPT_MODEL, **kwargs)\n",
    "    scores = vlm.compute_similarity_url(target_sg.image.url,results)\n",
    "    best_index = np.argmax(scores)\n",
    "    return results[best_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpt_execute(prompt_template, *args, **kwargs):            \n",
    "    prompt = prompt_template.format(*args)   \n",
    "    response = openai.Completion.create(prompt=prompt, max_tokens=256, **kwargs)   \n",
    "    # return response\n",
    "    return [x['text'].strip() for x in response['choices']]\n",
    "\n",
    "def generate_gpt_prompt(ids, target_id=None, pgen=GTBaseGenerator()):\n",
    "    rc = []\n",
    "    for id in ids:\n",
    "        rc.append(pgen.get_prompt(id,include_answer=True))\n",
    "    if target_id:\n",
    "        rc.append(pgen.get_prompt(target_id,include_answer=False))\n",
    "        print(\"Target id is: {}\".format(target_id))\n",
    "    return '\\n'.join(rc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_train, s3_test = np.split(np.array(s3_ids),[900])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = np.random.choice(s3_train,5)\n",
    "target_id = np.random.choice(s3_test)\n",
    "rc = generate_gpt_prompt(train_ids, target_id=target_id, pgen=base_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_rc = gpt_execute(rc,model=FS_GPT_MODEL,n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg = get_sc_graph(target_id)\n",
    "print(sg.image.url)\n",
    "gt_triplets = tuples_from_sg(sg)\n",
    "pred_triplets = spice_get_triplets(gpt_rc[0])\n",
    "recall = evaluator.recall_triplets_mean(gt_triplets,pred_triplets)\n",
    "print(\"Mean (bert-based) total recall of ground truth triplets in ipc triplets is: {}\".format(recall))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg = get_sc_graph(2359808)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(x.x, x.y, x.x+x.width, x.y+x.height) for x in sg.objects if x.width>=50 and x.height>=50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "senter = nlp.get_pipe(\"senter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = senter(nlp(\"Hello world. Hello world again.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(rc.sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dafab0f5b0f2e0b482ce484a64bf4a63ea947b97362cb54784af04b5754b7b41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
