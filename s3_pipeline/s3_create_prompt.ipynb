{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/notebooks/pipenv\")\n",
    "sys.path.insert(0, \"/notebooks/nebula3_database\")\n",
    "sys.path.insert(0, \"/notebooks/\")\n",
    "from PIL import Image\n",
    "import requests\n",
    "import visual_genome.local as vg\n",
    "import json\n",
    "import copy\n",
    "import subprocess\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import spacy\n",
    "import nltk\n",
    "from spacy_wordnet.wordnet_annotator import WordnetAnnotator \n",
    "from sentence_transformers import SentenceTransformer\n",
    "from database.arangodb import DatabaseConnector\n",
    "from config import NEBULA_CONF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "nlp.add_pipe(\"spacy_wordnet\", after='tagger', config={'lang': nlp.lang})\n",
    "\n",
    "VG_DATA = '/storage/vg_data'\n",
    "IPC_COLLECTION = 'ipc_relations_spice'\n",
    "RECALL_COLLECTION = 'ipc_recall_spice'\n",
    "GLOBAL_TOKENS_COLLECTION = 's3_global_tokens'\n",
    "\n",
    "class PIPELINE:\n",
    "    def __init__(self):\n",
    "        config = NEBULA_CONF()\n",
    "        self.db_host = config.get_database_host()\n",
    "        self.database = config.get_playground_name()\n",
    "        self.gdb = DatabaseConnector()\n",
    "        self.db = self.gdb.connect_db(self.database)\n",
    "\n",
    "pipeline = PIPELINE()\n",
    "ipc_data = json.load(open('/storage/ipc_data/paragraphs_v1.json','r'))\n",
    "def get_sc_graph(id):\n",
    "    return vg.get_scene_graph(id, images=VG_DATA,\n",
    "                    image_data_dir=VG_DATA+'/by-id/',\n",
    "                    synset_file=VG_DATA+'/synsets.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GTBaseGenerator:\n",
    "    def __init__(self):\n",
    "        self.pipeline = PIPELINE()\n",
    "\n",
    "    def get_image_id_from_collection(self, id,collection=GLOBAL_TOKENS_COLLECTION):\n",
    "        results = {}\n",
    "        query = 'FOR doc IN {} FILTER doc.image_id == {} RETURN doc'.format(collection,id)\n",
    "        #print(query)\n",
    "        cursor = self.pipeline.db.aql.execute(query)\n",
    "        for doc in cursor:\n",
    "            results.update(doc)\n",
    "        return results\n",
    "    \n",
    "    def get_structure(self, id):\n",
    "        sg = get_sc_graph(id)\n",
    "        global_doc = self.get_image_id_from_collection(id)\n",
    "        if not global_doc:\n",
    "            print(\"Couldn't find global tokens for id {}\".format(id))\n",
    "            return\n",
    "        rc_doc = {\n",
    "            'image_id': id,\n",
    "            'url': sg.image.url            \n",
    "        }\n",
    "        for (k,v) in global_doc.items():\n",
    "            if k.startswith('global'):\n",
    "                rc_doc[k]=copy.copy(v)\n",
    "        rois = []\n",
    "        for obj in sg.objects:\n",
    "            obj_dic = {\n",
    "                'GT': list(zip(obj.names,[1.0]*len(obj.names)))\n",
    "            }\n",
    "            attr_dic = {\n",
    "                'GT': list(zip(obj.attributes,[1.0]*len(obj.attributes)))\n",
    "            }\n",
    "            obj_doc = {                \n",
    "                'objects': obj.names,\n",
    "                'attributes': obj.attributes,\n",
    "                'bbox': [obj.x, obj.y, obj.x+obj.width, obj.y+obj.height]              \n",
    "                }\n",
    "            rois.append(obj_doc)\n",
    "        rc_doc['rois']=rois\n",
    "\n",
    "        return rc_doc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_gen = GTBaseGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2367862 in ipc\n",
    "id = 2367862\n",
    "rc = base_gen.get_structure(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'blip': 'a room with a computer and a chair and a chair'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rc['global_captions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 3871935,\n",
       " 'x': 0,\n",
       " 'y': 3,\n",
       " 'width': 498,\n",
       " 'height': 368,\n",
       " 'names': ['office'],\n",
       " 'synsets': [office.n.01 - place of business where professional or clerical duties are performed],\n",
       " 'attributes': []}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg.objects[0].__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = vg.get_all_region_descriptions(data_dir=VG_DATA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip([],[1.0]*0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('nebula')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dafab0f5b0f2e0b482ce484a64bf4a63ea947b97362cb54784af04b5754b7b41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
