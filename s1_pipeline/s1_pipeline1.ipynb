{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"/notebooks/pipenv\")\n",
    "sys.path.insert(0, \"/notebooks/nebula3_vlm\")\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import bisect\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "from typing import List, Tuple\n",
    "from operator import itemgetter \n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification, BertTokenizer, BertForSequenceClassification\n",
    "from database.arangodb import DatabaseConnector\n",
    "from config import NEBULA_CONF\n",
    "\n",
    "\n",
    "# BASE_DIR = os.path.abspath(os.getcwd()+'/../..')  # /home/gil/dev/NEBULA2/\n",
    "# os.chdir(os.getcwd()+'/../..')\n",
    "with open('/storage/keys/openai.key','r') as f:\n",
    "    OPENAI_API_KEY = f.readline().strip()\n",
    "openai.api_key = OPENAI_API_KEY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PIPELINE:\n",
    "    def __init__(self):\n",
    "        config = NEBULA_CONF()\n",
    "        self.db_host = config.get_database_host()\n",
    "        self.database = config.get_playground_name()\n",
    "        self.gdb = DatabaseConnector()\n",
    "        self.db = self.gdb.connect_db(self.database)\n",
    "\n",
    "pipeline = PIPELINE()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from database.arangodb import DatabaseConnector\n",
    "from movie_db import MOVIE_DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vlm.clip_api import CLIP_API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip=CLIP_API('vit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fusion_model=\"davinci:ft-personal:fusion-2022-03-29-21-07-19\"\n",
    "fusion_prompt_template=\"Original: {}\\nCandidates: {}\\n\\n###\\n\\n\"\n",
    "count_words = lambda s: len(s.split())\n",
    "\n",
    "def gpt_execute(prompt_template, *args, **kwargs):            \n",
    "    prompt = prompt_template.format(*args)   \n",
    "    response = openai.Completion.create(prompt=prompt, max_tokens=256, **kwargs)   \n",
    "    return response\n",
    "\n",
    "def gpt_fusion_ft(base, experts, **kwargs):\n",
    "    rc = gpt_execute(fusion_prompt_template, base, '; '.join(experts), stop=[\"\\n\"], model=fusion_model, **kwargs)\n",
    "    return [x['text'].strip() for x in rc['choices']]\n",
    "\n",
    "\n",
    "def gpt_batch_fusion(base, all_expert_combs, **kwargs):    \n",
    "    prompts = [fusion_prompt_template.format(base,'; '.join(exp)) for exp in all_expert_combs]\n",
    "    rc = openai.Completion.create(prompt=prompts, max_tokens=256, stop=[\"\\n\"], model=fusion_model, **kwargs)\n",
    "    rc_sentences = [x['text'].strip() for x in rc['choices']]\n",
    "    words_prompt = sum([count_words(x) for x in prompts])\n",
    "    words_completion = sum([count_words(x) for x in rc_sentences])        \n",
    "    return rc_sentences, words_prompt + words_completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PROMPT_NUM = 10\n",
    "MAX_RATE = 150000 / 5\n",
    "\n",
    "def gpt_process_fusion(base, all_experts, **kwargs):\n",
    "    rc = []\n",
    "    total_words = 0\n",
    "    start_time = time.time()\n",
    "    curr_rate = 0\n",
    "    flattened_experts = flatten(all_experts.values())\n",
    "    print(\"Total number of experts: {}\".format(len(flattened_experts)))\n",
    "    exp_combinations = [list(x) for x in list(itertools.combinations(flattened_experts,3)) + list(itertools.combinations(flattened_experts,2))]\n",
    "    # exp_combinations = [list(x) for x in list(itertools.combinations(flattened_experts,2))]\n",
    "    print(\"Total number of expert combinations: {}\".format(len(exp_combinations)))\n",
    "    chunked_experts=[exp_combinations[i:i + MAX_PROMPT_NUM] for i in range(0, len(exp_combinations), MAX_PROMPT_NUM)]\n",
    "    for experts in chunked_experts: \n",
    "        total_tokens = (total_words / 75) * 100\n",
    "        curr_time = time.time() - start_time\n",
    "        curr_rate = (total_tokens / curr_time) * 60        \n",
    "        print(\"Total words, tokens, time, rate: {}/{}/{}/{}\".format(total_words,total_tokens,curr_time,curr_rate))\n",
    "        while curr_rate>MAX_RATE:\n",
    "            print(\"Rate too high, going to sleep\")\n",
    "            time.sleep(5)\n",
    "            curr_time = time.time() - start_time\n",
    "            curr_rate = (total_tokens / curr_time) * 60 \n",
    "        done = False\n",
    "        while not done:\n",
    "            try:\n",
    "                fusion_results, num_words = gpt_batch_fusion(base, experts, **kwargs)\n",
    "                done=True\n",
    "            except Exception as e:\n",
    "                print('Error, re-trying')\n",
    "                print(e)\n",
    "                time.sleep(10)               \n",
    "        rc.extend(fusion_results)\n",
    "        total_words += num_words             \n",
    "\n",
    "    return rc, exp_combinations\n",
    "\n",
    "def process_scene(doc, max_sentences=10, n=1, **kwargs):\n",
    "    mid = doc['movie_id']\n",
    "    elem = doc['scene_element']\n",
    "    rc = nre.get_scene_from_collection(mid,elem,'s1_pipeline_results_phase2')\n",
    "    if rc and len(rc['combined_sentences']):\n",
    "        print(\"Results already exist for {}/{}\".format(mid,elem))\n",
    "        print(\"Length of output is {}\".format(len(rc['combined_sentences'])))\n",
    "        return\n",
    "    print(\"Going forward with {}/{}\".format(mid,elem))\n",
    "    done = False\n",
    "    while not done:\n",
    "        try:\n",
    "            rc, expert_combinations = gpt_process_fusion(doc['base'],doc['experts'], n=n, **kwargs)\n",
    "            done=True\n",
    "        except Exception as e:\n",
    "            print('process_scene: Error, re-trying')\n",
    "            time.sleep(20)\n",
    "    rc_doc = {\n",
    "        'movie_id': doc['movie_id'],\n",
    "        'scene_element': doc['scene_element'],\n",
    "        'combined_sentences': rc,\n",
    "        'ordered_experts': [val for val in expert_combinations for _ in range(n)]\n",
    "    }\n",
    "    query = \"INSERT {} INTO s1_pipeline_results_phase2\".format(rc_doc)\n",
    "    cursor = nre.db.aql.execute(query)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'FOR doc IN s1_lsmdc RETURN doc'\n",
    "cursor = pipeline.db.aql.execute(query)\n",
    "all_docs = list(cursor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_key': '135886559',\n",
       " '_id': 's1_lsmdc/135886559',\n",
       " '_rev': '_d1OEeR6---',\n",
       " 'ref': 'boat chase',\n",
       " 'movie_id': 'Movies/114208149',\n",
       " 'scene_element': 0,\n",
       " 'url': 'http://ec2-18-159-140-240.eu-central-1.compute.amazonaws.com:7000/static/development/1035_The_Adjustment_Bureau_00_01_40_825-00_01_46_814.mp4',\n",
       " 'base': ['A boat is traveling down the river in a city'],\n",
       " 'actions': ['be stationed in the city',\n",
       "  'rescue 4',\n",
       "  \"signal 13's arrival\",\n",
       "  'hijack a rescue boat',\n",
       "  'ascertain if the city is safe at all'],\n",
       " 'places': ['city', 'a city', 'an ocean liner', 'waterfront', 'ship'],\n",
       " 'experts': {'boat': ['red and white', 'speeds', 'water'],\n",
       "  'background': ['New York City buildings']},\n",
       " 'groundtruth': ['A red and white motorboat speeds with New York City buildings at the background']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_docs[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dafab0f5b0f2e0b482ce484a64bf4a63ea947b97362cb54784af04b5754b7b41"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit ('nebula': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
